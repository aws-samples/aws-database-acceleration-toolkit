{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"What is DAT?","text":"<p>The Database Acceleration Toolkit(DAT) is an open-source Infrastructure-as-a-code based (Terraform) single click solution to simplify and automate initial setup, provisioning (day 1) and on-going maintenance (day 2 operations) for Amazon Aurora database on AWS Cloud. </p> <p>It's designed to minimize the heavy lifting required for AWS customers to migrate from commercial databases such as SQL Server to Amazon Aurora and operating these databases in production.</p>"},{"location":"#key-features","title":"Key Features","text":"<p>Key features of DAT include automation of initial aurora setup and provisioning and on-going maintenance activities:</p> <ol> <li>Provisioning of new Aurora cluster</li> <li>Provisioning of new Aurora Global Database</li> <li>Monitoring Aurora database      a. Amazon CloudWatch     b. Amazon Managed Grafana     c. Curated CloudWatch and Grafana Dashboards     d. Curated Performance Insights Dashboard for both Amazon CloudWatch and Amazon Managed Grafana</li> <li>Provisioning and Integration with RDS Proxy to reuse database connections and improved reliability</li> <li>Provisioning of AWS Data Migration Services (DMS) Instances to migrate data to Aurora</li> <li>Restore cluster from S3</li> </ol>"},{"location":"contributing/","title":"Contributing Guidelines","text":"<p>Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community.</p> <p>Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution.</p>"},{"location":"contributing/#reporting-bugsfeature-requests","title":"Reporting Bugs/Feature Requests","text":"<p>We welcome you to use the GitHub issue tracker to report bugs or suggest features.</p> <p>When filing an issue, please check existing open, or recently closed, issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful:</p> <ul> <li>A reproducible test case or series of steps</li> <li>The version of our code being used</li> <li>Any modifications you've made relevant to the bug</li> <li>Anything unusual about your environment or deployment</li> </ul>"},{"location":"contributing/#contributing-via-pull-requests","title":"Contributing via Pull Requests","text":"<p>Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that:</p> <ol> <li>You are working against the latest source on the main branch.</li> <li>You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already.</li> <li>You open an issue to discuss any significant work - we would hate for your time to be wasted.</li> </ol> <p>To send us a pull request, please:</p> <ol> <li>Fork the repository.</li> <li>Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change.</li> <li>Ensure local tests pass.</li> <li>Commit to your fork using clear commit messages.</li> <li>Send us a pull request, answering any default questions in the pull request interface.</li> <li>Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation.</li> </ol> <p>GitHub provides additional document on forking a repository and creating a pull request.</p>"},{"location":"contributing/#finding-contributions-to-work-on","title":"Finding contributions to work on","text":"<p>Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels (enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.</p>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>This project has adopted the Amazon Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.</p>"},{"location":"contributing/#security-issue-notifications","title":"Security issue notifications","text":"<p>If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page. Please do not create a public github issue.</p>"},{"location":"contributing/#licensing","title":"Licensing","text":"<p>See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution.</p>"},{"location":"contributors/","title":"Contributors","text":"<p>The content on this site is maintained by the Solutions Architects and Technical Account Managers from the AWS observability team with support from the AWS service teams and other volunteers from across the organization.</p> <p>Our goal is to make it easier to use AWS Native and Open Source Observability Services.</p> <p>The core team include the following people, in alphabetical order:</p> <ul> <li>KK (Krishna) Venkateswaran</li> <li>Mitesh Purohit</li> <li>Munish Dabra</li> <li>Mythili Annamalai Seka</li> <li>Piyush Mattoo</li> <li>Prithvi Reddy</li> </ul> <p>We welcome the wider open source community to this project.</p> <p>Note that all information published on this site is available via the MIT-0 license.</p>"},{"location":"deploy/","title":"Deploy","text":""},{"location":"deploy/#deployment-steps","title":"Deployment Steps","text":"<p>The following steps will walk you through the deployment of <code>aurora-postgres-cluster-existing-vpc</code> example blueprint. This example expects you to leverage an existing VPC and provision a new Aurora Cluster with one writer and one reader instance. However you can customize the reader and writer instances:</p>"},{"location":"deploy/#step-1-clone-the-repo-using-the-command-below","title":"Step 1: Clone the repo using the command below","text":"<pre><code>git clone https://github.com/awsdabra/aurora-accelerator-for-terraform\n</code></pre>"},{"location":"deploy/#step-2-review-and-update-the-terraformtfvars","title":"Step 2: Review and update the terraform.tfvars","text":"<p>Navigate to <code>aurora-postgres-cluster-existing-vpc</code> under <code>examples</code> folder. </p> <p>```shell script cd examples/aurora-postgres-cluster-existing-vpc</p> <pre><code>Review the Terraform variable definition file called `terraform.tfvars` and update the values for the variables as per your use case. \n</code></pre>"},{"location":"deploy/#mandatory-aws-region-where-your-resources-will-be-located","title":"(mandatory) AWS Region where your resources will be located","text":"<p>region = \"\""},{"location":"deploy/#mandatory-vpc-id-where-your-database-and-other-aws-resources-will-be-located","title":"(mandatory) VPC Id where your database and other AWS resources will be located.","text":""},{"location":"deploy/#for-example-vpc-0759280xx50555743","title":"For example: \"vpc-0759280XX50555743\"","text":"<p>vpc_id = \"\""},{"location":"deploy/#mandatory-instance-class","title":"(mandatory) Instance class.","text":""},{"location":"deploy/#for-example-dbt4gmicro-is-a-free-tier-instance","title":"For example: \"db.t4g.micro\" is a free tier instance","text":"<p>instance_class =\"\""},{"location":"deploy/#mandatory-database-engine-for-your-aurora-cluster-options-aurora-postgresql-or-aurora-mysql","title":"(mandatory) Database Engine for your Aurora Cluster. Options: \"aurora-postgresql\" or \"aurora-mysql\"","text":""},{"location":"deploy/#for-example-aurora-postgresql","title":"For example: \"aurora-postgresql\"","text":"<p>engine = \"\""},{"location":"deploy/#mandatory-number-of-instances","title":"(mandatory) Number of instances","text":"<p>instances = {     one   = {}     two   = {} }</p>"},{"location":"deploy/#optional-default-is-provisioned-database-cluster-for-serverless-select-serverless","title":"(optional) Default is \"provisioned\" database cluster; For serverless, select \"serverless\"","text":"<p>engine_mode = \"\""},{"location":"deploy/#optional-the-database-engine-version-note-updating-this-argument-results-in-an-outage","title":"(optional) The database engine version. Note -Updating this argument results in an outage\"","text":""},{"location":"deploy/#for-example-153","title":"For example: \"15.3\"","text":"<p>engine_version = \"\""},{"location":"deploy/#optional-database-cluster-name-for-example-aurora-pg-poc","title":"(optional) Database cluster name, for example 'aurora-pg-poc'","text":""},{"location":"deploy/#for-example-aurora-pg-poc","title":"For example: \"aurora-pg-poc\"","text":"<p>name = \"\""},{"location":"deploy/#optional-database-environment","title":"(optional) Database environment","text":""},{"location":"deploy/#for-example-dev","title":"For example: \"dev\"","text":"<p>environment = \"\""},{"location":"deploy/#optional-tagging-teamgroup-name","title":"(optional) Tagging : Team/Group Name","text":""},{"location":"deploy/#for-example-dev_1","title":"For example: \"dev\"","text":"<p>groupname = \"\""},{"location":"deploy/#optional-tagging-project-or-application-name","title":"(optional) Tagging : Project or Application Name","text":""},{"location":"deploy/#for-example-dev_2","title":"For example: \"dev\"","text":"<p>project = \"\" <pre><code>The example below illustrates how to use the 'region' variable to define the AWS region for your database-related resources.\n```shell script\nregion = \"us-east-2\"\n</code></pre>"},{"location":"deploy/#step-3-run-terraform-init","title":"Step 3: Run Terraform INIT","text":"<p>Initialize a working directory with configuration files by running <code>terraform init</code> </p> <p>```shell script terraform init</p> <pre><code>### Step 4: Run Terraform PLAN\nVerify the resources created by this execution using `terraform plan`\n\n```shell script\nterraform plan -var-file terraform.tfvars\n</code></pre>"},{"location":"deploy/#step-5-terraform-apply","title":"Step 5: Terraform APPLY","text":"<p>To create resources by running <code>terraform apply</code> commands</p> <p>```shell script terraform apply -var-file terraform.tfvars</p> <pre><code>### Cleanup: Terraform DESTROY\n\nTo clean up your environment, destroy the AWS resources created \n\n```sh\nterraform destroy -var-file terraform.tfvars\n</code></pre>"},{"location":"faq/","title":"FAQ","text":"<ul> <li>[Is DAT an open-source solution?)</li> <li>[Who are the intended audience for DAT?)</li> <li>[What DB Engines are currently supported?)</li> <li>[How will customer deploy the solution?)</li> <li>[Is there any cost associated with using DAT?)</li> <li>[Is there any community or support for DAT?)</li> </ul>"},{"location":"faq/#is-dat-an-open-source-solution","title":"Is DAT an open-source solution?","text":"<p>Yes, DAT is an open-source solution that customers can use and customize according to their needs.</p>"},{"location":"faq/#who-are-the-intended-audiences-for-dat","title":"Who are the intended audiences for DAT?","text":"<p>The intended audiences for DAT are AWS customers who are migrating from commercial databases such as SQL Server to Amazon Aurora.</p>"},{"location":"faq/#what-db-engines-are-currently-supported","title":"What DB Engines are currently supported?","text":"<p>Currently, we support PostgreSQL only. MySQL database engine is on the short-term roadmap.</p>"},{"location":"faq/#how-will-customer-deploy-the-solution","title":"How will customer deploy the solution?","text":"<p>Customers will be able to download DAT as a IaC template from Github as one-click deployment.</p>"},{"location":"faq/#is-there-any-cost-associated-with-using-dat","title":"Is there any cost associated with using DAT?","text":"<p>No, DAT is an open-source solution and is completely free to use. However, you will be responsible for any AWS costs associated with running your Aurora clusters and other AWS services.</p>"},{"location":"faq/#is-there-any-community-or-support-for-dat","title":"Is there any community or support for DAT?","text":"<p>DAT is supported by Solution Architects of AWS on best effort basis. However, users are encourged to ask questions, open issues, contribute and provide feedback on DAT.</p>"},{"location":"getstarted/","title":"Getting Started","text":""},{"location":"getstarted/#getting-started","title":"Getting Started","text":"<p>This section demonstrate how you can leverage DAT to provision new cluster.</p>"},{"location":"getstarted/#prerequisites","title":"Prerequisites","text":"<p>First, ensure that you have installed the following tools locally.</p> <ol> <li>aws cli</li> <li>kubectl</li> <li>terraform</li> </ol>"},{"location":"getstarted/#deployment-steps","title":"Deployment Steps","text":"<p>The following steps will walk you through the deployment of <code>aurora-postgres-cluster-existing-vpc</code> example blueprint. This example expects you to leverage an existing VPC and provision a new Aurora Cluster with one writer and one reader instance. However you can customize the reader and writer instances:</p>"},{"location":"getstarted/#step-1-clone-the-repo-using-the-command-below","title":"Step 1: Clone the repo using the command below","text":"<pre><code>git clone https://github.com/awsdabra/aurora-accelerator-for-terraform\n</code></pre>"},{"location":"getstarted/#step-2-review-and-update-the-terraformtfvars","title":"Step 2: Review and update the terraform.tfvars","text":"<p>Navigate to <code>aurora-postgres-cluster-existing-vpc</code> under <code>examples</code> folder. </p> <p>```shell script cd examples/aurora-postgres-cluster-existing-vpc</p> <pre><code>Review the Terraform variable definition file called `terraform.tfvars` and update the values for the variables as per your use case. \n</code></pre>"},{"location":"getstarted/#mandatory-aws-region-where-your-resources-will-be-located","title":"(mandatory) AWS Region where your resources will be located","text":"<p>region = \"\""},{"location":"getstarted/#mandatory-vpc-id-where-your-database-and-other-aws-resources-will-be-located","title":"(mandatory) VPC Id where your database and other AWS resources will be located.","text":""},{"location":"getstarted/#for-example-vpc-0759280xx50555743","title":"For example: \"vpc-0759280XX50555743\"","text":"<p>vpc_id = \"\""},{"location":"getstarted/#mandatory-instance-class","title":"(mandatory) Instance class.","text":""},{"location":"getstarted/#for-example-dbt4gmicro-is-a-free-tier-instance","title":"For example: \"db.t4g.micro\" is a free tier instance","text":"<p>instance_class =\"\""},{"location":"getstarted/#mandatory-database-engine-for-your-aurora-cluster-options-aurora-postgresql-or-aurora-mysql","title":"(mandatory) Database Engine for your Aurora Cluster. Options: \"aurora-postgresql\" or \"aurora-mysql\"","text":""},{"location":"getstarted/#for-example-aurora-postgresql","title":"For example: \"aurora-postgresql\"","text":"<p>engine = \"\""},{"location":"getstarted/#mandatory-number-of-instances","title":"(mandatory) Number of instances","text":"<p>instances = {     one   = {}     two   = {} }</p>"},{"location":"getstarted/#optional-default-is-provisioned-database-cluster-for-serverless-select-serverless","title":"(optional) Default is \"provisioned\" database cluster; For serverless, select \"serverless\"","text":"<p>engine_mode = \"\""},{"location":"getstarted/#optional-the-database-engine-version-note-updating-this-argument-results-in-an-outage","title":"(optional) The database engine version. Note -Updating this argument results in an outage\"","text":""},{"location":"getstarted/#for-example-153","title":"For example: \"15.3\"","text":"<p>engine_version = \"\""},{"location":"getstarted/#optional-database-cluster-name-for-example-aurora-pg-poc","title":"(optional) Database cluster name, for example 'aurora-pg-poc'","text":""},{"location":"getstarted/#for-example-aurora-pg-poc","title":"For example: \"aurora-pg-poc\"","text":"<p>name = \"\""},{"location":"getstarted/#optional-database-environment","title":"(optional) Database environment","text":""},{"location":"getstarted/#for-example-dev","title":"For example: \"dev\"","text":"<p>environment = \"\""},{"location":"getstarted/#optional-tagging-teamgroup-name","title":"(optional) Tagging : Team/Group Name","text":""},{"location":"getstarted/#for-example-dev_1","title":"For example: \"dev\"","text":"<p>groupname = \"\""},{"location":"getstarted/#optional-tagging-project-or-application-name","title":"(optional) Tagging : Project or Application Name","text":""},{"location":"getstarted/#for-example-dev_2","title":"For example: \"dev\"","text":"<p>project = \"\" <pre><code>The example below illustrates how to use the 'region' variable to define the AWS region for your database-related resources.\n```shell script\nregion = \"us-east-2\"\n</code></pre>"},{"location":"getstarted/#step-3-run-terraform-init","title":"Step 3: Run Terraform INIT","text":"<p>Initialize a working directory with configuration files by running <code>terraform init</code> </p> <p>```shell script terraform init</p> <pre><code>### Step 4: Run Terraform PLAN\nVerify the resources created by this execution using `terraform plan`\n\n```shell script\nterraform plan -var-file terraform.tfvars\n</code></pre>"},{"location":"getstarted/#step-5-terraform-apply","title":"Step 5: Terraform APPLY","text":"<p>To create resources by running <code>terraform apply</code> commands</p> <p>```shell script terraform apply -var-file terraform.tfvars</p> <pre><code>### Cleanup: Terraform DESTROY\n\nTo clean up your environment, destroy the AWS resources created \n\n```sh\nterraform destroy -var-file terraform.tfvars\n</code></pre>"}]}